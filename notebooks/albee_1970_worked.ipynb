{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cL8sVxbKicbW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL8sVxbKicbW",
        "outputId": "c9c28da3-6123-4eac-e799-2497e2aa0ee9"
      },
      "outputs": [],
      "source": [
        "!pip install pdfplumber pandas numpy\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "\n",
        "PDF_PATH = \"/content/albee_et_al_1970.pdf\"\n",
        "PAGES_1INDEXED = [6, 7]\n",
        "\n",
        "TARGET = [\"SiO2\", \"MgO\", \"FeO\", \"MnO\", \"CaO\", \"Cr2O3\"]\n",
        "NUM_RE = re.compile(r\"^[\\(\\-]?\\d+(?:\\.\\d+)?[\\)]?$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e10aac4-6e6b-429f-b933-474b40f5c76f",
      "metadata": {
        "id": "9e10aac4-6e6b-429f-b933-474b40f5c76f"
      },
      "outputs": [],
      "source": [
        "def canon_oxide(s: str):\n",
        "    t = str(s).strip().lower().replace(\" \", \"\")\n",
        "    t = t.replace(\"s102\",\"sio2\").replace(\"si02\",\"sio2\").replace(\"sioz\",\"sio2\")\n",
        "    t = t.replace(\"fe0\",\"feo\")\n",
        "    t = t.replace(\"cr203\",\"cr2o3\").replace(\"cr2o8\",\"cr2o3\")\n",
        "    if t.startswith(\"sio2\"): return \"SiO2\"\n",
        "    if t.startswith(\"mgo\"):  return \"MgO\"\n",
        "    if t.startswith(\"feo\"):  return \"FeO\"\n",
        "    if t.startswith(\"mno\"):  return \"MnO\"\n",
        "    if t.startswith(\"cao\"):  return \"CaO\"\n",
        "    if t.startswith(\"cr2o3\"):return \"Cr2O3\"\n",
        "    return None\n",
        "\n",
        "def is_number_token(s: str):\n",
        "    s2 = str(s).replace(\",\", \"\").strip()\n",
        "    return bool(NUM_RE.match(s2))\n",
        "\n",
        "def to_float(s: str):\n",
        "    return float(str(s).replace(\",\", \"\").strip().strip(\"()\"))\n",
        "\n",
        "def cluster_1d(vals, tol):\n",
        "    \"\"\"Return cluster centers for 1D values.\"\"\"\n",
        "    vals = sorted(vals)\n",
        "    centers = []\n",
        "    for v in vals:\n",
        "        if not centers or abs(centers[-1][\"c\"] - v) > tol:\n",
        "            centers.append({\"c\": v, \"n\": 1})\n",
        "        else:\n",
        "            centers[-1][\"c\"] = (centers[-1][\"c\"]*centers[-1][\"n\"] + v)/(centers[-1][\"n\"]+1)\n",
        "            centers[-1][\"n\"] += 1\n",
        "    return [c[\"c\"] for c in centers]\n",
        "\n",
        "def group_words_into_rows(words, y_tol=3.0):\n",
        "    \"\"\"\n",
        "    Group words into rows using y-center clustering.\n",
        "    Returns list of rows; each row is list of word dicts sorted by x0.\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    for w in words:\n",
        "        yc = (w[\"top\"] + w[\"bottom\"]) / 2\n",
        "        items.append((yc, w))\n",
        "    items.sort(key=lambda t: t[0])\n",
        "\n",
        "    rows = []\n",
        "    for yc, w in items:\n",
        "        placed = False\n",
        "        for r in rows:\n",
        "            if abs(r[\"yc\"] - yc) <= y_tol:\n",
        "                r[\"words\"].append(w)\n",
        "                # update center\n",
        "                r[\"yc\"] = (r[\"yc\"]*r[\"n\"] + yc)/(r[\"n\"]+1)\n",
        "                r[\"n\"] += 1\n",
        "                placed = True\n",
        "                break\n",
        "        if not placed:\n",
        "            rows.append({\"yc\": yc, \"n\": 1, \"words\": [w]})\n",
        "\n",
        "    out = []\n",
        "    for r in rows:\n",
        "        r[\"words\"].sort(key=lambda w: w[\"x0\"])\n",
        "        out.append(r[\"words\"])\n",
        "    return out\n",
        "\n",
        "def find_header_band(words, max_lines=40):\n",
        "    \"\"\"\n",
        "    Find the top header band likely containing mineral names.\n",
        "    We look for a row containing 'olivine' and at least one other capitalized mineral-ish word.\n",
        "    \"\"\"\n",
        "    rows = group_words_into_rows(words, y_tol=4.0)\n",
        "    for row in rows[:max_lines]:\n",
        "        texts = [w[\"text\"] for w in row]\n",
        "        low = [t.lower() for t in texts]\n",
        "        if any(\"olivine\" in t for t in low):\n",
        "            return row\n",
        "    return None\n",
        "\n",
        "def olivine_x_bounds_from_header_row(header_row):\n",
        "    \"\"\"\n",
        "    Use the header row containing mineral names.\n",
        "    Bound olivine block as:\n",
        "      left = olivine x0 - small pad\n",
        "      right = next header token x0 - small pad  (prevents leaking into next mineral block)\n",
        "    If no next header, right = olivine x1 + conservative pad.\n",
        "    \"\"\"\n",
        "    # sort by x\n",
        "    hdr = sorted(header_row, key=lambda w: w[\"x0\"])\n",
        "    # find olivine token(s)\n",
        "    olv_idx = [i for i,w in enumerate(hdr) if \"olivine\" in w[\"text\"].lower()]\n",
        "    if not olv_idx:\n",
        "        return None\n",
        "\n",
        "    i0 = olv_idx[0]\n",
        "    left = hdr[i0][\"x0\"] - 5\n",
        "\n",
        "    # next \"header-ish\" token to the right (skip tiny symbols/numbers)\n",
        "    right = None\n",
        "    for j in range(i0+1, len(hdr)):\n",
        "        t = hdr[j][\"text\"].strip()\n",
        "        if not t:\n",
        "            continue\n",
        "        # skip numeric column labels if any\n",
        "        if is_number_token(t):\n",
        "            continue\n",
        "        # skip very short punctuation\n",
        "        if len(t) <= 1:\n",
        "            continue\n",
        "        right = hdr[j][\"x0\"] - 5\n",
        "        break\n",
        "\n",
        "    if right is None:\n",
        "        right = hdr[i0][\"x1\"] + 140  # conservative if no neighbor header\n",
        "    return left, right, hdr[i0][\"top\"], hdr[i0][\"bottom\"]\n",
        "\n",
        "def extract_olivine_only_page(pl_page, debug=False):\n",
        "    words = pl_page.extract_words(keep_blank_chars=False, use_text_flow=True)\n",
        "    header_row = find_header_band(words)\n",
        "    if header_row is None:\n",
        "        if debug: print(\"No header row with 'Olivine' found.\")\n",
        "        return pd.DataFrame(columns=[\"page\",\"olivine_col_idx\"] + TARGET)\n",
        "\n",
        "    bounds = olivine_x_bounds_from_header_row(header_row)\n",
        "    if bounds is None:\n",
        "        if debug: print(\"No olivine bounds.\")\n",
        "        return pd.DataFrame(columns=[\"page\",\"olivine_col_idx\"] + TARGET)\n",
        "\n",
        "    xL, xR, yH_top, yH_bot = bounds\n",
        "    # data region starts below header\n",
        "    y_data_top = yH_bot + 5\n",
        "    # take most of the page downward (safe); stop before footer if needed\n",
        "    y_data_bot = pl_page.height - 30\n",
        "\n",
        "    if debug:\n",
        "        print(\"page\", pl_page.page_number, \"xL,xR:\", (xL,xR), \"y_data:\", (y_data_top,y_data_bot))\n",
        "\n",
        "    # crop words to the olivine data block\n",
        "    block = [w for w in words if (xL <= w[\"x0\"] <= xR) and (y_data_top <= w[\"top\"] <= y_data_bot)]\n",
        "    # also need oxide labels on left of block, so collect label words from full page but within y region\n",
        "    left_band = [w for w in words if (w[\"x0\"] < xL) and (y_data_top <= w[\"top\"] <= y_data_bot)]\n",
        "\n",
        "    # group rows for robust row alignment\n",
        "    rows_block = group_words_into_rows(block, y_tol=3.0)\n",
        "    rows_left  = group_words_into_rows(left_band, y_tol=3.0)\n",
        "\n",
        "    # build mapping from row yc -> oxide label (from left_band rows)\n",
        "    # use closest row match in y between left labels and block rows\n",
        "    left_labels = []\n",
        "    for r in rows_left:\n",
        "        if not r:\n",
        "            continue\n",
        "        # take left-most word as potential label\n",
        "        w0 = r[0]\n",
        "        ox = canon_oxide(w0[\"text\"])\n",
        "        if ox:\n",
        "            yc = (w0[\"top\"] + w0[\"bottom\"]) / 2\n",
        "            left_labels.append((yc, ox))\n",
        "\n",
        "    if debug:\n",
        "        print(\"oxide labels found:\", sorted(set(ox for _,ox in left_labels)))\n",
        "\n",
        "    # helper: find closest label for a block row y\n",
        "    def closest_label(yc):\n",
        "        if not left_labels:\n",
        "            return None\n",
        "        return min(left_labels, key=lambda t: abs(t[0]-yc))[1] if min(abs(t[0]-yc) for t in left_labels) < 10 else None\n",
        "\n",
        "    # find the SiO2 row inside olivine block to infer column centers\n",
        "    sio2_row_words = None\n",
        "    sio2_row_yc = None\n",
        "    for r in rows_block:\n",
        "        if not r: continue\n",
        "        yc = (r[0][\"top\"] + r[0][\"bottom\"]) / 2\n",
        "        ox = closest_label(yc)\n",
        "        if ox == \"SiO2\":\n",
        "            sio2_row_words = r\n",
        "            sio2_row_yc = yc\n",
        "            break\n",
        "\n",
        "    if sio2_row_words is None:\n",
        "        if debug: print(\"No SiO2 row aligned; cannot infer columns.\")\n",
        "        return pd.DataFrame(columns=[\"page\",\"olivine_col_idx\"] + TARGET)\n",
        "\n",
        "    # infer analysis column x-centers from numeric tokens in SiO2 row (within olivine block)\n",
        "    sio2_nums = [w for w in sio2_row_words if is_number_token(w[\"text\"])]\n",
        "    col_xs = cluster_1d([ (w[\"x0\"]+w[\"x1\"])/2 for w in sio2_nums ], tol=18.0)\n",
        "    if debug:\n",
        "        print(\"inferred olivine analysis columns:\", len(col_xs), col_xs)\n",
        "\n",
        "    if not col_xs:\n",
        "        return pd.DataFrame(columns=[\"page\",\"olivine_col_idx\"] + TARGET)\n",
        "\n",
        "    # build oxide->row_words mapping for rows that align to oxide labels\n",
        "    oxide_to_row = {}\n",
        "    for r in rows_block:\n",
        "        if not r: continue\n",
        "        yc = (r[0][\"top\"] + r[0][\"bottom\"]) / 2\n",
        "        ox = closest_label(yc)\n",
        "        if ox in TARGET and ox not in oxide_to_row:\n",
        "            oxide_to_row[ox] = r\n",
        "\n",
        "    # extract values per column center per oxide\n",
        "    records = []\n",
        "    for j, cx in enumerate(col_xs, start=1):\n",
        "        rec = {\"page\": pl_page.page_number, \"olivine_col_idx\": j}\n",
        "        for ox in TARGET:\n",
        "            r = oxide_to_row.get(ox)\n",
        "            if not r:\n",
        "                rec[ox] = np.nan\n",
        "                continue\n",
        "            nums = [w for w in r if is_number_token(w[\"text\"])]\n",
        "            # pick closest numeric token in x to column center, but only within this row\n",
        "            best, best_dx = None, 1e9\n",
        "            for w in nums:\n",
        "                xw = (w[\"x0\"]+w[\"x1\"])/2\n",
        "                dx = abs(xw - cx)\n",
        "                if dx < best_dx:\n",
        "                    best_dx, best = dx, w\n",
        "            if best is None or best_dx > 25:\n",
        "                rec[ox] = np.nan\n",
        "            else:\n",
        "                rec[ox] = to_float(best[\"text\"])\n",
        "        # keep columns that have enough oxides\n",
        "        if sum(pd.notna(rec[k]) for k in TARGET) >= 3:\n",
        "            records.append(rec)\n",
        "\n",
        "    return pd.DataFrame(records, columns=[\"page\",\"olivine_col_idx\"] + TARGET)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4e6e473-b21c-4667-979f-98fe50c9c5d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "f4e6e473-b21c-4667-979f-98fe50c9c5d3",
        "outputId": "edafd055-86ba-443f-8546-d85bcf6cb114"
      },
      "outputs": [],
      "source": [
        "dfs = []\n",
        "with pdfplumber.open(PDF_PATH) as pdf:\n",
        "    for p1 in PAGES_1INDEXED:\n",
        "        dfs.append(extract_olivine_only_page(pdf.pages[p1-1], debug=True))\n",
        "\n",
        "df_olivine = pd.concat(dfs, ignore_index=True)\n",
        "display(df_olivine)\n",
        "\n",
        "df_olivine.to_csv(\"albee_1970_pages6_7_olivine_only.csv\", index=False)\n",
        "print(\"Wrote albee_1970_pages6_7_olivine_only.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a3a215c-32a8-40a8-bef7-f5092758eb62",
      "metadata": {
        "id": "9a3a215c-32a8-40a8-bef7-f5092758eb62"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
